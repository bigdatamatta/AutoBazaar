{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artefact-1-sentence-embed-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03d9188776f74acdab0180461be1740d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c00295d05434346819df46cadc64ced",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c7903784e384a8298c983a0e3dad987",
              "IPY_MODEL_4e1251c8606441dbadcf51c310481af9"
            ]
          }
        },
        "70796202be334932972d86ccf69f69b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_75276496d26b4b9fb949171d2ae536d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93541b82fb8d486497d1030c5134317f",
              "IPY_MODEL_85ef837e64224581922827fedfc74146"
            ]
          }
        },
        "5709c6013c2c44db82e620cc5b3009cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f4e0b3613354955a8cf06481b427e86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1dc2ba8f0e7a4fbf84d8e9d4220ad5ee",
              "IPY_MODEL_bab7586d21bf4f9292ee56556968823b"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigdatamatta/AutoBazaar/blob/master/artefact_1_sentence_embed_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rMXYMxqVT1F",
        "colab_type": "text"
      },
      "source": [
        "## EXPERIMENT 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdlsTX6dwCsD",
        "colab_type": "code",
        "outputId": "9888093c-8456-4035-dcb8-1f4fd9a5d748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 2.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 38.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=fdce885d06b92f9261bc8c7aaa84cde3dbd45b52a8ea6876b3364a76a349b6d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFG55uv0wIC9",
        "colab_type": "code",
        "outputId": "385c1237-c06d-47b7-e328-d0eb194fa216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertConfig, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59xN9RNeGym5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function for getting segments\n",
        "def get_segments(tokens):\n",
        "    #print(\"get_segments\")\n",
        "    #print(tokens)\n",
        "    seg_ids = []\n",
        "    current_seg_id = 0\n",
        "    for tok in tokens:\n",
        "        seg_ids.append(current_seg_id)\n",
        "        if tok == \"[SEP]\":\n",
        "            current_seg_id = 1-current_seg_id \n",
        "    return (seg_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXgmhB3xG9TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ids(tokens, tokenizer):\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzZpNGiTHAb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(sent, tokenizer):\n",
        "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HtHhqgXHCmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(model_string = 'bert-base-uncased'):\n",
        "  config = BertConfig.from_pretrained(model_string, output_hidden_states=True)\n",
        "  model = BertModel.from_pretrained(model_string, config=config)\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_string)\n",
        "  return (model, tokenizer, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD9bDBFaHGC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence_embedding(sent, model, tokenizer, config):\n",
        "\n",
        "  tokens = encode_sentence(sent, tokenizer)\n",
        "  segments_idx = get_segments(tokens)\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_idx])\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs  = model(tokens_tensor, segments_tensors)\n",
        "  embeddings_of_last_layer = outputs[0]\n",
        "  cls_embeddings = embeddings_of_last_layer[0]\n",
        "  last_hidden_states = outputs[0] \n",
        "  hidden_states = outputs[2]\n",
        "  embedding_output = hidden_states[0]\n",
        "  encoded_layers = attention_hidden_states = hidden_states[1:]\n",
        "  # BERT has twelve (in this case) layers, we are considering Second Last layer.\n",
        "  #token_vecs = encoded_layers[10][0] # encoded_layers[11][0]\n",
        "  token_vecs = cls_embeddings\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0) # Calculating average across the sentence.\n",
        "  return(sentence_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ntn6r_OJedd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_document_embedding(lstdocuments, model, tokenizer, config ):\n",
        "  docembeddings = []\n",
        "  for doc in lstdocuments:\n",
        "    docembeddings.append(get_sentence_embedding(doc, model, tokenizer, config))\n",
        "  return(docembeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ybshbgVJkR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst_corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'Sachin Tendulkar is a great player.',\n",
        "          'Sholay is an Indian classic film',\n",
        "          'Dog is hunting for food'\n",
        "          ]\n",
        "test_sentences = [\"Cricket is my favourite game.\", \"I like hindi movies.\", \"Cat is looking to eat\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfLc6L4sJ1XB",
        "colab_type": "code",
        "outputId": "f5e51fba-1206-4130-8e1e-274b2a3ae066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "03d9188776f74acdab0180461be1740d",
            "70796202be334932972d86ccf69f69b8",
            "5709c6013c2c44db82e620cc5b3009cf",
            "6c00295d05434346819df46cadc64ced",
            "5c7903784e384a8298c983a0e3dad987",
            "4e1251c8606441dbadcf51c310481af9",
            "75276496d26b4b9fb949171d2ae536d3",
            "93541b82fb8d486497d1030c5134317f",
            "85ef837e64224581922827fedfc74146",
            "6f4e0b3613354955a8cf06481b427e86",
            "1dc2ba8f0e7a4fbf84d8e9d4220ad5ee",
            "bab7586d21bf4f9292ee56556968823b"
          ]
        }
      },
      "source": [
        "model, tokenizer, config = get_model();\n",
        "test_embeds = get_document_embedding(test_sentences, model, tokenizer, config)\n",
        "doc_embeds = get_document_embedding(lst_corpus, model, tokenizer, config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03d9188776f74acdab0180461be1740d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70796202be334932972d86ccf69f69b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5709c6013c2c44db82e620cc5b3009cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUP6l-m5J8Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBfNU7F3KYpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_distances(query_embedding, document_emdeddings):\n",
        "  distances_c = []  \n",
        "  for docembed in document_emdeddings:\n",
        "    distances_c.append(scipy.spatial.distance.cosine(query_embedding, docembed))\n",
        "  return(distances_c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5duPJWiKKegX",
        "colab_type": "code",
        "outputId": "19599438-bfa4-4c2d-d0fe-aec7910d43f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "closest_n = 3\n",
        "for query, query_embedding in zip(test_sentences, test_embeds):\n",
        "    distances = calculate_distances(query_embedding, doc_embeds)\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop %s most similar sentences in corpus:\\n\" % closest_n)\n",
        "\n",
        "    for idx, distance in results[0:closest_n]:\n",
        "        print(lst_corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: Cricket is my favourite game.\n",
            "\n",
            "Top 3 most similar sentences in corpus:\n",
            "\n",
            "A monkey is playing drums. (Score: 0.6063)\n",
            "Sachin Tendulkar is a great player. (Score: 0.6003)\n",
            "A woman is playing violin. (Score: 0.5699)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: I like hindi movies.\n",
            "\n",
            "Top 3 most similar sentences in corpus:\n",
            "\n",
            "A monkey is playing drums. (Score: 0.6127)\n",
            "A man is eating food. (Score: 0.6020)\n",
            "A woman is playing violin. (Score: 0.5987)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: Cat is looking to eat\n",
            "\n",
            "Top 3 most similar sentences in corpus:\n",
            "\n",
            "A man is eating food. (Score: 0.6959)\n",
            "Dog is hunting for food (Score: 0.6752)\n",
            "The girl is carrying a baby. (Score: 0.6217)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4D3CSpcOit2",
        "colab_type": "text"
      },
      "source": [
        "### EXPERIMENT 1A : TESTING BERT FOR WORD CONTEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JU9rS9iOpJ1",
        "colab_type": "code",
        "outputId": "6d84b83b-868d-43c9-cdf6-b30a5b166bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
        "       \"fishing on the Mississippi river bank.\"\n",
        "\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs  = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "hidden_states = outputs[2]\n",
        "print(len(hidden_states))  # 13\n",
        "\n",
        "embedding_output = hidden_states[0]\n",
        "attention_hidden_states = hidden_states[1:]\n",
        "token_embeddings = torch.stack(attention_hidden_states, dim=0)\n",
        "token_embeddings.size()\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings.size()\n",
        "token_embeddings = token_embeddings.permute(1,0,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9_4b03PO_PG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsLUHgzyOqi4",
        "colab_type": "code",
        "outputId": "582ddc3d-7ee9-41d9-bb09-687e7d9624c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "tokenized_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'after',\n",
              " 'stealing',\n",
              " 'money',\n",
              " 'from',\n",
              " 'the',\n",
              " 'bank',\n",
              " 'vault',\n",
              " ',',\n",
              " 'the',\n",
              " 'bank',\n",
              " 'robber',\n",
              " 'was',\n",
              " 'seen',\n",
              " 'fishing',\n",
              " 'on',\n",
              " 'the',\n",
              " 'mississippi',\n",
              " 'river',\n",
              " 'bank',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3t63ENKOsG_",
        "colab_type": "code",
        "outputId": "0e573750-8165-44d2-ee29-c80cb7367f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow2LpEOmP5aN",
        "colab_type": "code",
        "outputId": "47dba5c5-7d83-4cd1-87d2-c7d7f22968d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YebT4C3VQHbJ",
        "colab_type": "code",
        "outputId": "4c61d030-2463-4977-b357-b4af915a44a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank \n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}